{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training:\n",
    "# 1) Load all data from preprocessing (training/test splits, etc)\n",
    "# 2) Begin Training Models\n",
    "    #  a) Decision Tree\n",
    "    #  b) Naive Bayes\n",
    "    #  c) Logistic Regression\n",
    "    #  d) SVM\n",
    "# 3) Testing Models\n",
    "# 4) New Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from Models import ModelUtil\n",
    "from Data import Preprocessing, DataUtil\n",
    "# from Visualization import VisualUtil, batch_image_to_excel\n",
    "from Logs import logging as logs\n",
    "\n",
    "import importlib\n",
    "import configparser\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('Data//config.ini')\n",
    "\n",
    "importlib.reload(Preprocessing)\n",
    "importlib.reload(ModelUtil)\n",
    "# importlib.reload(VisualUtil)\n",
    "# importlib.reload(batch_image_to_excel)\n",
    "importlib.reload(logs)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load all data from preprocessing \n",
    "importlib.reload(Preprocessing)\n",
    "newprocessing = 'True' in config['DATA']['USE_NEW_PREPROCESSING']\n",
    "infieldDataFrame, outfieldDataFrame = Preprocessing.dataFiltering([], newprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of Empty DataFrame\n",
      "Columns: [PitcherThrows, BatterSide, TaggedPitchType, PlateLocHeight, PlateLocSide, ZoneSpeed, RelSpeed, VertRelAngle, HorzRelAngle, SpinRate, SpinAxis, RelHeight, RelSide, VertBreak, InducedVertBreak, HorzBreak, VertApprAngle, HorzApprAngle, Extension, FieldSection, PitcherTeam]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 21 columns]>\n",
      "<bound method NDFrame.head of Empty DataFrame\n",
      "Columns: [PitcherThrows, BatterSide, TaggedPitchType, PlateLocHeight, PlateLocSide, ZoneSpeed, RelSpeed, VertRelAngle, HorzRelAngle, SpinRate, SpinAxis, RelHeight, RelSide, VertBreak, InducedVertBreak, HorzBreak, VertApprAngle, HorzApprAngle, Extension, FieldSlice, PitcherTeam]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 21 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(outfieldDataFrame.head)\n",
    "print(infieldDataFrame.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of this is mapping the strings to numbers for both infieldDataFrame and outfieldDataFrame so that the correlation matrix can be computed\n",
    "# This can most likely be moved to a method in the logging.py file\n",
    "infieldDF4Matrix = infieldDataFrame.copy()\n",
    "outfieldDF4Matrix = outfieldDataFrame.copy()\n",
    "strColumns = [] \n",
    "for cName in outfieldDF4Matrix.columns:\n",
    "    if(str(outfieldDF4Matrix[cName].dtype) in 'object'):\n",
    "        strColumns.append(cName)\n",
    "rValueDict = {}\n",
    "for cName in strColumns:\n",
    "    i = 0\n",
    "    infieldUniques = infieldDF4Matrix[cName].unique()\n",
    "    for rValue in infieldUniques:\n",
    "        rValueDict.update({rValue:i})\n",
    "        i+=1\n",
    "    infieldDF4Matrix[cName] = infieldDF4Matrix[cName].map(rValueDict)\n",
    "    uniqueVals = [x for x in outfieldDF4Matrix[cName].unique() if x not in infieldUniques]\n",
    "    for rValue in uniqueVals: \n",
    "        rValueDict.update({rValue:i})\n",
    "        i+=1\n",
    "    outfieldDF4Matrix[cName] = outfieldDF4Matrix[cName].map(rValueDict)\n",
    "infieldDF4Matrix = infieldDF4Matrix.replace(np.nan, 0)\n",
    "infieldDF4Matrix = infieldDF4Matrix.replace('', 0)\n",
    "outfieldDF4Matrix = outfieldDF4Matrix.replace(np.nan, 0)\n",
    "outfieldDF4Matrix = outfieldDF4Matrix.replace('', 0)\n",
    "\n",
    "# Correlation does not imply causation.\n",
    "# -1 means that the 2 variables have an inverse linear relationship: when X increases, Y decreases\n",
    "# 0 means no linear correlation between X and Y\n",
    "# 1 means that the 2 variables have a linear relationship: when X increases, Y increases too.\n",
    "infieldcorrmatrix = infieldDF4Matrix.corr()\n",
    "outfieldcorrmatrix = outfieldDF4Matrix.corr()\n",
    "if (config['LOGGING']['Excel'] == 'True'):\n",
    "    logs.writeToExcelSheet(infieldcorrmatrix, \"Infield Correlation Matrix\")\n",
    "    logs.writeToExcelSheet(outfieldcorrmatrix, \"Outfield Correlation Matrix\")\n",
    "if (config['LOGGING']['Debug'] == 'True'):\n",
    "    print(infieldcorrmatrix)\n",
    "    print(outfieldcorrmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m gamma\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     15\u001b[0m coef0\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 16\u001b[0m xoTrain, xoTest, yoTrain, yoTest \u001b[38;5;241m=\u001b[39m \u001b[43mModelUtil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodelDataSplitting\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutfieldDataFrame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOutfieldTrainingFilter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOutfield\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(yoTrain\u001b[38;5;241m.\u001b[39mhead)\n\u001b[1;32m     18\u001b[0m OutfielddtOutput \u001b[38;5;241m=\u001b[39m ModelUtil\u001b[38;5;241m.\u001b[39mrunDT(xoTrain, yoTrain, xoTest, yoTest, max_depth, max_features, max_leaf_nodes, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutfield\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Senior Design Files/shifting_model/Models/ModelUtil.py:635\u001b[0m, in \u001b[0;36mmodelDataSplitting\u001b[0;34m(dF, randomState, testSize, dFType, fieldModelType)\u001b[0m\n\u001b[1;32m    633\u001b[0m originalNotNormX \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    634\u001b[0m X \u001b[38;5;241m=\u001b[39m DataUtil\u001b[38;5;241m.\u001b[39mnormalizeData(X, originalNotNormX)\n\u001b[0;32m--> 635\u001b[0m xTrain, xTest, yTrain, yTest \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtestSize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandomState\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;66;03m# adb = AdaBoostClassifier()\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;66;03m# adb_model = adb.fit(xTrain, yTrain)\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \n\u001b[1;32m    639\u001b[0m \u001b[38;5;66;03m# calculate split information:\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m yTrain:\n",
      "File \u001b[0;32m~/Desktop/Senior Design Files/shifting_model/environment/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Senior Design Files/shifting_model/environment/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2660\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2657\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2659\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2660\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2662\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2665\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Senior Design Files/shifting_model/environment/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2308\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2305\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2309\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2312\u001b[0m     )\n\u001b[1;32m   2314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "importlib.reload(logs)\n",
    "importlib.reload(ModelUtil)\n",
    "# 2) Trains all Models and exports all data to an Excel Sheet\n",
    "max_depth = 50\n",
    "max_features = 30\n",
    "max_leaf_nodes = 150\n",
    "# could also add ways to change it for these hyperparams below for other models\n",
    "var_smoothing = 1e-9\n",
    "lr = 0.8\n",
    "e = 100\n",
    "rC = 1\n",
    "kernel='linear'\n",
    "degree= 1\n",
    "gamma= 'scale'\n",
    "coef0= 0.0\n",
    "xoTrain, xoTest, yoTrain, yoTest = ModelUtil.modelDataSplitting(outfieldDataFrame, 11, 0.25,'OutfieldTrainingFilter', \"Outfield\")\n",
    "print(yoTrain.head)\n",
    "OutfielddtOutput = ModelUtil.runDT(xoTrain, yoTrain, xoTest, yoTest, max_depth, max_features, max_leaf_nodes, \"Outfield\")\n",
    "OutfieldnbOutput = ModelUtil.runNB(xoTrain, yoTrain, xoTest, yoTest, var_smoothing, \"Outfield\")\n",
    "OutfieldlogRegOutput = ModelUtil.runLogReg(xoTrain, yoTrain, xoTest, yoTest, lr, e, \"Outfield\")\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = ModelUtil.modelDataSplitting(infieldDataFrame, 11, 0.25,'InfieldTrainingFilter', \"Infield\")\n",
    "dtOutput = ModelUtil.runDT(xTrain, yTrain, xTest, yTest, max_depth, max_features, max_leaf_nodes, \"Infield\")\n",
    "nbOutput = ModelUtil.runNB(xTrain, yTrain, xTest, yTest, var_smoothing, \"Infield\")\n",
    "logRegOutput = ModelUtil.runLogReg(xTrain, yTrain, xTest, yTest, lr, e, \"Infield\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(logs)\n",
    "# 2) Trains all Models and exports all data to an Excel Sheet\n",
    "max_depth = 50\n",
    "max_features = 30\n",
    "max_leaf_nodes = 150\n",
    "# could also add ways to change it for these hyperparams below for other models\n",
    "var_smoothing = 1e-9\n",
    "lr = 0.8\n",
    "e = 100\n",
    "rC = 1\n",
    "kernel='linear'\n",
    "degree= 1\n",
    "gamma= 'scale'\n",
    "coef0= 0.0\n",
    "\n",
    "runCount = int(config['TRAIN']['TimesRun'])\n",
    "if (\"False\" in config['TRAIN']['Testing']):\n",
    "     runCount = 1\n",
    "     print(\"Not Testing\")\n",
    "for j in range(1, runCount+1):\n",
    "        xTrain, xTest, yTrain, yTest = ModelUtil.modelDataSplitting(infieldDataFrame, j, 0.25,'InfieldTrainingFilter')\n",
    "        if(\"True\" in config['MODELS']['DTC']):\n",
    "            dtOutput = ModelUtil.runDT(xTrain, yTrain, xTest, yTest, max_depth, max_features, max_leaf_nodes)\n",
    "            if (\"True\" in config['DATA']['Pickle']):\n",
    "                # Save the model to a file\n",
    "                with open('Models/DecisionTree.pkl', 'wb') as file:\n",
    "                  pickle.dump(dtOutput, file)\n",
    "        if(\"True\" in config['MODELS']['NB']):   \n",
    "            nbOutput = ModelUtil.runNB(xTrain, yTrain, xTest, yTest, var_smoothing)\n",
    "            if (\"True\" in config['DATA']['Pickle']):\n",
    "                # Save the model to a file\n",
    "                with open('Models/NaiveBayes.pkl', 'wb') as file:\n",
    "                  pickle.dump(nbOutput, file)\n",
    "        if(\"True\" in config['MODELS']['LR']):\n",
    "            logRegOutput = ModelUtil.runLogReg(xTrain, yTrain, xTest, yTest, lr, e)\n",
    "            if (\"True\" in config['DATA']['Pickle']):\n",
    "                # Save the model to a file\n",
    "                with open('Models/LogRegression.pkl', 'wb') as file:\n",
    "                  pickle.dump(logRegOutput, file)\n",
    "        if(\"True\" in config['MODELS']['SVM']):\n",
    "            svmOutput = ModelUtil.runSVM(xTrain, yTrain, xTest, yTest, rC, kernel, degree, gamma, coef0)\n",
    "            if (\"True\" in config['DATA']['Pickle']):\n",
    "                # Save the model to a file\n",
    "                with open('Models/SVM.pkl', 'wb') as file:\n",
    "                  pickle.dump(svmOutput, file)\n",
    "        # if(\"True\" in config['MODELS']['RF']):\n",
    "        #     for i in range(0, len(trainIn)):\n",
    "        #         direction, distance = ModelUtil.runRFR(trainIn[i], trainOut[i], testIn[i], testOut[i])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# a) Decision Tree\n",
    "# Need to test these hyperparameters for best case\n",
    "# Maybe make a way to superset these\n",
    "max_depth =      [50, 40]\n",
    "max_features =   [30, 20]\n",
    "max_leaf_nodes = [150, 100]\n",
    "hyperparamlist = []\n",
    "# This just makes the permutations of the hyperparameters above. Lets you test on many hyperparams.\n",
    "for n in range(len(max_depth)):\n",
    "    for k in range(len(max_features)):\n",
    "        for m in range(len(max_leaf_nodes)):\n",
    "            hyperparamlist.append([max_depth[n], max_features[k], max_leaf_nodes[m]])\n",
    "            \n",
    "# for each permutation, it runs a certain amount of time that you specify in the config (30 rn bc of Dozier) and saves the outcome to an excel sheet\n",
    "# requires to rerun the training set every time because otherwise will give you the same outcome every time\n",
    "# Also proves that its the models ability, not the luck of the draw for the data\n",
    "for lst in hyperparamlist:\n",
    "    runCount = int(config['TRAIN']['TimesRun'])\n",
    "    if (\"False\" in config['TRAIN']['Testing']):\n",
    "        runCount = 1\n",
    "        print(\"Not Testing\")\n",
    "    for j in range(runCount):\n",
    "        print(infieldDataFrame)\n",
    "        xTrain, xTest, yTrain, yTest = ModelUtil.modelDataSplitting(infieldDataFrame, j, 0.25,'InfieldTrainingFilter')\n",
    "        dtOutput = ModelUtil.runDT(xTrain, yTrain, xTest, yTest, lst[0], lst[1], lst[2])\n",
    "        if (\"True\" in config['DATA']['Pickle']):\n",
    "            # Save the model to a file\n",
    "            with open('Models/DecisionTree.pkl', 'wb') as file:\n",
    "                pickle.dump(dtOutput, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# b) Naive Bayes\n",
    "\n",
    "var_smoothing = 1e-9\n",
    "runCount = int(config['TRAIN']['TimesRun'])\n",
    "if (\"False\" in config['TRAIN']['Testing']):\n",
    "     runCount = 1\n",
    "     print(\"Not Testing\")\n",
    "for j in range(1, runCount+1):\n",
    "        xTrain, xTest, yTrain, yTest = ModelUtil.modelDataSplitting(infieldDataFrame, j, 0.25,'InfieldTrainingFilter')\n",
    "        nbOutput = ModelUtil.runNB(xTrain, yTrain, xTest, yTest, var_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# c)Logistic Regression\n",
    "lr = 0.8\n",
    "e = 100\n",
    "runCount = int(config['TRAIN']['TimesRun'])\n",
    "if (\"False\" in config['TRAIN']['Testing']):\n",
    "     runCount = 1\n",
    "     print(\"Not Testing\")\n",
    "for j in range(1, runCount+1):\n",
    "     xTrain, xTest, yTrain, yTest = ModelUtil.modelDataSplitting(infieldDataFrame, j, 0.25,'InfieldTrainingFilter')\n",
    "     logRegOutput = ModelUtil.runLogReg(xTrain, yTrain, xTest, yTest, lr, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# d) SVM\n",
    "rC = 1\n",
    "kernel='linear'\n",
    "degree= 1\n",
    "gamma= 'scale'\n",
    "coef0= 0.0\n",
    "runCount = int(config['TRAIN']['TimesRun'])\n",
    "if (\"False\" in config['TRAIN']['Testing']):\n",
    "     runCount = 1\n",
    "     print(\"Not Testing\")\n",
    "for j in range(1,runCount+1):\n",
    "     xTrain, xTest, yTrain, yTest = ModelUtil.modelDataSplitting(infieldDataFrame, j, 0.25,'InfieldTrainingFilter')\n",
    "     svmOutput = ModelUtil.runSVM(xTrain, yTrain, xTest, yTest, rC, kernel, degree, gamma, coef0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # z) RandomForestRegressor\n",
    "# for i in range(0, len(trainIn)):\n",
    "#     direction, distance = ModelUtil.runRFR(trainIn[i], trainOut[i], testIn[i], testOut[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# This is meant to take all the values from the 30 runs and average them and output them to another sheet of averages for different models\n",
    "# Then will need to do this for all the models\n",
    "# Can take this and put it into an excelAverages function\n",
    "#prob rename this\n",
    "\n",
    "# could move these column letter names and do something with that so not hardcoded\n",
    "if(\"True\" in config['LOGGING']['Excel']):\n",
    "    sColumns = ['Training Accuracy', 'Testing Accuracy', 'Training Average Error', 'Testing Average Error', 'Training F1(micro)', 'Training F1(macro)', 'Training F1(weighted)', \n",
    "                'Testing F1(micro)', 'Testing F1(macro)', 'Testing F1(weighted)', 'Training AUC(macro)', 'Training AUC(weighted)', 'Testing AUC(macro)', 'Testing AUC(weighted)', \n",
    "                'Section 0 Probability', 'Section 1 Probability', 'Section 2 Probability', 'Section 3 Probability', 'Section 4 Probability']\n",
    "    if(\"True\" in config['MODELS']['DTC']):\n",
    "        # columns in excel: I J K L W X Y Z AA AB AC AD AE AF AG AH AI AJ AK   \n",
    "        sColumnsLetter = ['I','J','K','L','W','X','Y','Z','AA','AB','AC','AD','AE','AF','AG','AH','AI','AJ','AK']\n",
    "        logs.excelAverages('DecisionTree',sColumns,sColumnsLetter)\n",
    "    if(\"True\" in config['MODELS']['NB']):\n",
    "        sColumnsLetter = ['D','E','F','G','R','S','T','U','V','W','X','Y','Z','AA','AB','AC','AD','AE','AF']\n",
    "        logs.excelAverages('NaiveBayes',sColumns,sColumnsLetter)\n",
    "    if(\"True\" in config['MODELS']['LR']):\n",
    "        sColumnsLetter = ['E','F','G','H','S','T','U','V','W','X','Y','Z','AA','AB','AC','AD','AE','AF','AG']\n",
    "        logs.excelAverages('LogisticRegression',sColumns,sColumnsLetter)\n",
    "    if(\"True\" in config['MODELS']['SVM']):\n",
    "        sColumnsLetter = ['H','I','J','K','V','W','X','Y','Z','AA','AB','AC','AD','AE','AF','AG','AH','AI','AJ']\n",
    "        logs.excelAverages('SVM',sColumns,sColumnsLetter)\n",
    "    if(\"True\" in config['MODELS']['RF']):\n",
    "        logs.excelAverages('RandomForest',sColumns,sColumnsLetter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the value of index to look at different datapoints\n",
    "importlib.reload(VisualUtil)\n",
    "# 3) Model Testing:\n",
    "dt = dtOutput[0]\n",
    "nb = nbOutput[0]\n",
    "logReg = logRegOutput[0]\n",
    "# svm = svmOutput[0]\n",
    "\n",
    "print(\"Testing Output: \")\n",
    "# index of test value:\n",
    "index = 4555\n",
    "print(f\"Actual Field Slice: \\t\\t{yTest.iloc[index]}\")\n",
    "\n",
    "print(\"\\nDecision Tree:\")\n",
    "print(f\"Predicted Field Slice: \\t\\t{dt.predict([xTest.iloc[index]])[0]}\")\n",
    "print(f\"Field Slice Probabilities: \\t{dt.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "print(\"\\nNaive Bayes:\")\n",
    "print(f\"Predicted Field Slice: \\t\\t{nb.predict([xTest.iloc[index]])[0]}\")\n",
    "print(f\"Field Slice Probabilities: \\t{nb.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print(f\"Predicted Field Slice: \\t\\t{logReg.predict([xTest.iloc[index]])[0]}\")\n",
    "print(f\"Field Slice Probabilities: \\t{logReg.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "# print(\"\\nSVM:\")\n",
    "# print(f\"Predicted Field Slice: \\t\\t{svm.predict([xTest.iloc[index]])[0]}\")\n",
    "# print(f\"Field Slice Probabilities: \\t{svm.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "averageProbs = dt.predict_proba([xTest.iloc[index]])[0] + nb.predict_proba([xTest.iloc[index]])[0] + logReg.predict_proba([xTest.iloc[index]])[0] # + svm.predict_proba([xTest.iloc[index]])[0]\n",
    "averageProbs = averageProbs / 3 \n",
    "\n",
    "print(f\"\\n\\nAVG Prediction: \\t\\t{np.argmax(averageProbs)+1}\")\n",
    "print(f\"Field Slice AVG Probabilities: \\t{averageProbs}\")\n",
    "\n",
    "VisualUtil.visualizeData(averageProbs, [1], 'TestPic.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Data Visualization\n",
    "importlib.reload(VisualUtil)\n",
    "\n",
    "# Temporary method of getting percentages for testing purposes\n",
    "infieldPercentages  = np.random.dirichlet(np.ones(5), size=1)[0]\n",
    "outfieldPercentages = np.random.dirichlet(np.ones(2), size=1)[0]\n",
    "outfieldCoordinates = np.random.uniform(low=[-45, 150], high=[45, 400], size=(30,2))\n",
    "\n",
    "outfieldCoordinates = [0,1,0,0,3,0,0,0,0,0,0,0,0,5,0]\n",
    "VisualUtil.visualizeData(infieldPercentages, outfieldCoordinates, \"FieldTest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [0,1,2,3]\n",
    "o = [2,3,4,5]\n",
    "\n",
    "print(l+o)\n",
    "l.append(o)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Pitcher Data Processing and Running\n",
    "importlib.reload(Preprocessing)\n",
    "importlib.reload(DataUtil)\n",
    "importlib.reload(VisualUtil)\n",
    "importlib.reload(batch_image_to_excel)\n",
    "importlib.reload(logs)\n",
    "\n",
    "\n",
    "pitchingAveragesDF = DataUtil.getRawDataFrame('Data/PitchMetricAverages_AsOf_2024-03-11.csv', [])\n",
    "# drop nan values from the used columns\n",
    "specific_columns = [\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"RelSpeed\", \"InducedVertBreak\", \"HorzBreak\", \"RelHeight\", \"RelSide\", \"SpinAxis\", \"SpinRate\", \"VertApprAngle\", \"HorzApprAngle\"] # pitcher averages\n",
    "infieldDataFrame = infieldDataFrame[specific_columns] \n",
    "outfieldDataFrame = outfieldDataFrame[specific_columns]\n",
    "averagesX = pitchingAveragesDF[specific_columns] # pitcher averages\n",
    "#averagesX = averagesX.dropna(axis=0, how='any',subset=specific_columns)\n",
    "#averagesX = averagesX[[\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"PlateLocHeight\", \"PlateLocSide\", \"ZoneSpeed\", \"RelSpeed\", \"SpinRate\", \"HorzBreak\", \"VertBreak\"]]\n",
    "\n",
    "averagesX[\"PitcherThrows\"] = averagesX[\"PitcherThrows\"].map({\"Left\":1, \"Right\":2, \"Both\":3})\n",
    "averagesX[\"BatterSide\"] = averagesX[\"BatterSide\"].map({\"Left\":1, \"Right\":2})\n",
    "averagesX[\"TaggedPitchType\"] = averagesX[\"TaggedPitchType\"].map({\"Fastball\": 1, \"FourSeamFastBall\":1, \"Sinker\":2, \"TwoSeamFastBall\":2, \"Cutter\":3, \"Curveball\":4, \"Slider\":5, \"ChangeUp\":6, \"Splitter\":7, \"Knuckleball\":8})\n",
    "\n",
    "# normalize this based on min and maxes from training data\n",
    "averagesX = DataUtil.normalizeData(averagesX, infieldDataFrame)\n",
    "\n",
    "# Change the value of index to look at different datapoints\n",
    "importlib.reload(VisualUtil)\n",
    "# 3) Model Testing:\n",
    "dt = dtOutput[0]\n",
    "nb = nbOutput[0]\n",
    "logReg = logRegOutput[0]\n",
    "dto = OutfielddtOutput[0]\n",
    "nbo = OutfieldnbOutput[0]\n",
    "logRego = OutfieldlogRegOutput[0]\n",
    "# svm = svmOutput[0]\n",
    "for index in range(pitchingAveragesDF.shape[0]):\n",
    "    #print(index)\n",
    "    averageProbs= []\n",
    "    averageProbs = dt.predict_proba([averagesX.iloc[index]])[0] + nb.predict_proba([averagesX.iloc[index]])[0] + logReg.predict_proba([averagesX.iloc[index]])[0]\n",
    "    averageProbs = averageProbs / 3 \n",
    "\n",
    "    averageProbso= []\n",
    "    averageProbso = dto.predict_proba([averagesX.iloc[index]])[0] + nbo.predict_proba([averagesX.iloc[index]])[0] + logRego.predict_proba([averagesX.iloc[index]])[0]\n",
    "    averageProbso = averageProbso / 3 \n",
    "\n",
    "    # print(f\"\\n\\nAVG Prediction: \\t\\t{np.argmax(averageProbs)+1}\")\n",
    "    # print(f\"Field Slice AVG Probabilities: \\t{averageProbs}\")\n",
    "    fileName = pitchingAveragesDF.iloc[index][0].replace(\",\", \"_\").replace(\" \", \"\") + \"_\" + pitchingAveragesDF.iloc[index][\"TaggedPitchType\"] + \"_\" + pitchingAveragesDF.iloc[index][\"BatterSide\"] + \"Batter\"\n",
    "    VisualUtil.visualizeData(averageProbs, averageProbso, fileName)   \n",
    "\n",
    "batch_image_to_excel.create_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Pitcher Data Processing and Running\n",
    "importlib.reload(Preprocessing)\n",
    "importlib.reload(DataUtil)\n",
    "importlib.reload(VisualUtil)\n",
    "importlib.reload(batch_image_to_excel)\n",
    "import math\n",
    "\n",
    "\n",
    "pitchingAveragesDF = DataUtil.getRawDataFrame('Data/PitchMetricAverages_AsOf_2024-03-11.csv', [])\n",
    "# drop nan values from the used columns\n",
    "specific_columns = [\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"RelSpeed\", \"InducedVertBreak\", \"HorzBreak\", \"RelHeight\", \"RelSide\", \"SpinAxis\", \"SpinRate\", \"VertApprAngle\", \"HorzApprAngle\"]#, \"Extension\"] # pitcher averages\n",
    "outfieldDataFrame = outfieldDataFrame[specific_columns] \n",
    "infieldDataFrame = infieldDataFrame[specific_columns]\n",
    "averagesX = pitchingAveragesDF[specific_columns] # pitcher averages\n",
    "#averagesX = averagesX[[\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"PlateLocHeight\", \"PlateLocSide\", \"ZoneSpeed\", \"RelSpeed\", \"SpinRate\", \"HorzBreak\", \"VertBreak\"]]\n",
    "averagesX[\"PitcherThrows\"] = averagesX[\"PitcherThrows\"].map({\"Left\":1, \"Right\":2, \"Both\":3})\n",
    "averagesX[\"BatterSide\"] = averagesX[\"BatterSide\"].map({\"Left\":1, \"Right\":2})\n",
    "averagesX[\"TaggedPitchType\"] = averagesX[\"TaggedPitchType\"].map({\"Fastball\": 1, \"FourSeamFastBall\":1, \"Sinker\":2, \"TwoSeamFastBall\":2, \"Cutter\":3, \"Curveball\":4, \"Slider\":5, \"ChangeUp\":6, \"Splitter\":7, \"Knuckleball\":8})\n",
    "\n",
    "# normalize this based on min and maxes from training data\n",
    "averagesX = DataUtil.normalizeData(averagesX, infieldDataFrame)\n",
    "\n",
    "# Change the value of index to look at different datapoints\n",
    "importlib.reload(VisualUtil)\n",
    "# 3) Model Testing:\n",
    "dt = dtOutput[0]\n",
    "nb = nbOutput[0]\n",
    "logReg = logRegOutput[0]\n",
    "\n",
    "dto = OutfielddtOutput[0]\n",
    "nbo = OutfieldnbOutput[0]\n",
    "logRego = OutfieldlogRegOutput[0]\n",
    "# svm = svmOutput[0]\n",
    "for index in range(pitchingAveragesDF.shape[0]):\n",
    "    #print(index)\n",
    "    averageProbs= []\n",
    "    averageProbs = dt.predict_proba([averagesX.iloc[index]])[0] + nb.predict_proba([averagesX.iloc[index]])[0] + logReg.predict_proba([averagesX.iloc[index]])[0]\n",
    "    averageProbs = averageProbs / 3 \n",
    "\n",
    "    averageProbso= []\n",
    "    averageProbso = dto.predict_proba([averagesX.iloc[index]])[0] + nbo.predict_proba([averagesX.iloc[index]])[0] + logRego.predict_proba([averagesX.iloc[index]])[0]\n",
    "    averageProbso = averageProbso / 3 \n",
    "\n",
    "    # print(f\"\\n\\nAVG Prediction: \\t\\t{np.argmax(averageProbs)+1}\")\n",
    "    # print(f\"Field Slice AVG Probabilities: \\t{averageProbs}\")\n",
    "    fileName = pitchingAveragesDF.iloc[index][0].replace(\",\", \"_\").replace(\" \", \"\") + \"_\" + pitchingAveragesDF.iloc[index][\"TaggedPitchType\"] + \"_\" + pitchingAveragesDF.iloc[index][\"BatterSide\"] + \"Batter\"\n",
    "    VisualUtil.visualizeData(averageProbs, averageProbso, fileName)   \n",
    "\n",
    "batch_image_to_excel.create_excel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
